{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MS0OQk83pfHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84248eb5-904a-4d58-e314-231bb3081a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf dataset"
      ],
      "metadata": {
        "id": "K4EZ3SH6y183"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Change the path to your dataset folder\n",
        "dataset_path = '/content/drive/MyDrive/Colab Notebooks/IOT_Malware_dataset'\n",
        "os.chdir(dataset_path)\n"
      ],
      "metadata": {
        "id": "thyYOIK7q5bu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set the paths\n",
        "base_dir = '/content/drive/MyDrive/Colab Notebooks/IOT_Malware_dataset'\n",
        "benign_dir = os.path.join(base_dir, 'Benign')\n",
        "malware_dir = os.path.join(base_dir, 'Malware')\n",
        "\n",
        "# Get the list of image files\n",
        "benign_images = [os.path.join(benign_dir, img) for img in os.listdir(benign_dir)]\n",
        "malware_images = [os.path.join(malware_dir, img) for img in os.listdir(malware_dir)]\n",
        "\n",
        "# Choose an equal number of images from both classes\n",
        "num_images = min(len(benign_images), len(malware_images))\n",
        "\n",
        "# Use only the number of malware images that matches the number of benign images\n",
        "malware_images = malware_images[:num_images]\n",
        "print(len(malware_images))\n",
        "print(len(benign_images))\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_benign, test_benign = train_test_split(benign_images, test_size=0.2, random_state=42)\n",
        "train_malware, test_malware = train_test_split(malware_images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create train and test directories\n",
        "train_dir = '/content/dataset/train/'\n",
        "test_dir = '/content/dataset/test/'\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, \"Benign\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, \"Malware\"), exist_ok=True)\n",
        "\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "os.makedirs(os.path.join(test_dir, \"Benign\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(test_dir, \"Malware\"), exist_ok=True)\n",
        "\n",
        "# Copy images to train and test directories\n",
        "for img in train_benign:\n",
        "    os.system(f'cp \"{img}\" \"{os.path.join(train_dir, \"Benign\")}\"')\n",
        "\n",
        "for img in train_malware:\n",
        "    os.system(f'cp \"{img}\" \"{os.path.join(train_dir, \"Malware\")}\"')\n",
        "\n",
        "for img in test_benign:\n",
        "    os.system(f'cp \"{img}\" \"{os.path.join(test_dir, \"Benign\")}\"')\n",
        "\n",
        "for img in test_malware:\n",
        "    os.system(f'cp \"{img}\" \"{os.path.join(test_dir, \"Malware\")}\"')\n",
        "\n",
        "# Set up image data generators for train and test sets\n",
        "batch_size = 32\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw3mjQsqsqxo",
        "outputId": "c8f2bfff-0f7e-43aa-a4fd-128f3b07c3ce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2486\n",
            "2486\n",
            "Found 3976 images belonging to 2 classes.\n",
            "Found 996 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Function to create, compile, train, and save model with a given optimizer\n",
        "def train_and_save_model(optimizer_name, optimizer, train_generator, test_generator):\n",
        "    # Load the VGG16 model and remove the final layer\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Create a new model by combining the VGG16 base model and the new layers\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Freeze the VGG16 base layers and train the new layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print(f\"\\nTraining model with optimizer: {optimizer_name}\")\n",
        "\n",
        "    model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples // batch_size,\n",
        "        epochs=20,\n",
        "        validation_data=test_generator,\n",
        "        validation_steps=test_generator.samples // batch_size\n",
        "    )\n",
        "\n",
        "    # Save the model\n",
        "    model.save(f'/content/drive/MyDrive/Colab Notebooks/malware_detector_vgg16_{optimizer_name}.h5')\n",
        "\n",
        "# Set up image data generators for train and test sets\n",
        "batch_size = 32\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# List of optimizers to try\n",
        "optimizers = ['adam', 'adamax', 'adadelta', 'rmsprop']\n",
        "\n",
        "# Train and save models with different optimizers\n",
        "for optimizer_name in optimizers:\n",
        "    optimizer = optimizer_name\n",
        "    train_and_save_model(optimizer_name, optimizer, train_generator, test_generator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOjG3uDPv_mA",
        "outputId": "87ada222-4d75-497d-c432-faa1567213f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3976 images belonging to 2 classes.\n",
            "Found 996 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 3s 0us/step\n",
            "\n",
            "Training model with optimizer: adam\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-165a74a5d06c>:36: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124/124 [==============================] - 33s 181ms/step - loss: 0.4448 - accuracy: 0.8570 - val_loss: 0.2334 - val_accuracy: 0.8911\n",
            "Epoch 2/20\n",
            "124/124 [==============================] - 20s 160ms/step - loss: 0.2307 - accuracy: 0.9057 - val_loss: 0.1990 - val_accuracy: 0.9113\n",
            "Epoch 3/20\n",
            "124/124 [==============================] - 19s 151ms/step - loss: 0.2055 - accuracy: 0.9166 - val_loss: 0.2243 - val_accuracy: 0.9143\n",
            "Epoch 4/20\n",
            "124/124 [==============================] - 20s 163ms/step - loss: 0.1966 - accuracy: 0.9120 - val_loss: 0.1827 - val_accuracy: 0.9254\n",
            "Epoch 5/20\n",
            "124/124 [==============================] - 19s 154ms/step - loss: 0.1586 - accuracy: 0.9369 - val_loss: 0.2125 - val_accuracy: 0.9022\n",
            "Epoch 6/20\n",
            "124/124 [==============================] - 19s 156ms/step - loss: 0.1492 - accuracy: 0.9394 - val_loss: 0.1790 - val_accuracy: 0.9304\n",
            "Epoch 7/20\n",
            "124/124 [==============================] - 21s 168ms/step - loss: 0.1587 - accuracy: 0.9374 - val_loss: 0.1725 - val_accuracy: 0.9244\n",
            "Epoch 8/20\n",
            "124/124 [==============================] - 21s 170ms/step - loss: 0.1448 - accuracy: 0.9393 - val_loss: 0.1763 - val_accuracy: 0.9284\n",
            "Epoch 9/20\n",
            "124/124 [==============================] - 21s 169ms/step - loss: 0.1392 - accuracy: 0.9375 - val_loss: 0.1719 - val_accuracy: 0.9274\n",
            "Epoch 10/20\n",
            "124/124 [==============================] - 21s 172ms/step - loss: 0.1338 - accuracy: 0.9424 - val_loss: 0.1639 - val_accuracy: 0.9425\n",
            "Epoch 11/20\n",
            "124/124 [==============================] - 21s 172ms/step - loss: 0.1333 - accuracy: 0.9452 - val_loss: 0.1721 - val_accuracy: 0.9345\n",
            "Epoch 12/20\n",
            "124/124 [==============================] - 21s 169ms/step - loss: 0.1352 - accuracy: 0.9478 - val_loss: 0.2219 - val_accuracy: 0.9143\n",
            "Epoch 13/20\n",
            "124/124 [==============================] - 21s 168ms/step - loss: 0.1212 - accuracy: 0.9465 - val_loss: 0.1812 - val_accuracy: 0.9315\n",
            "Epoch 14/20\n",
            "124/124 [==============================] - 22s 173ms/step - loss: 0.1194 - accuracy: 0.9498 - val_loss: 0.1903 - val_accuracy: 0.9325\n",
            "Epoch 15/20\n",
            "124/124 [==============================] - 21s 168ms/step - loss: 0.1008 - accuracy: 0.9589 - val_loss: 0.1928 - val_accuracy: 0.9315\n",
            "Epoch 16/20\n",
            "124/124 [==============================] - 22s 173ms/step - loss: 0.1303 - accuracy: 0.9450 - val_loss: 0.1654 - val_accuracy: 0.9375\n",
            "Epoch 17/20\n",
            "124/124 [==============================] - 20s 161ms/step - loss: 0.1199 - accuracy: 0.9475 - val_loss: 0.1850 - val_accuracy: 0.9385\n",
            "Epoch 18/20\n",
            "124/124 [==============================] - 21s 169ms/step - loss: 0.1061 - accuracy: 0.9485 - val_loss: 0.1957 - val_accuracy: 0.9345\n",
            "Epoch 19/20\n",
            "124/124 [==============================] - 21s 168ms/step - loss: 0.1011 - accuracy: 0.9561 - val_loss: 0.1927 - val_accuracy: 0.9294\n",
            "Epoch 20/20\n",
            "124/124 [==============================] - 21s 173ms/step - loss: 0.0951 - accuracy: 0.9541 - val_loss: 0.1721 - val_accuracy: 0.9355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model with optimizer: adamax\n",
            "Epoch 1/20\n",
            "124/124 [==============================] - 22s 171ms/step - loss: 0.3964 - accuracy: 0.8671 - val_loss: 0.2378 - val_accuracy: 0.8921\n",
            "Epoch 2/20\n",
            "124/124 [==============================] - 20s 164ms/step - loss: 0.2158 - accuracy: 0.9077 - val_loss: 0.2026 - val_accuracy: 0.9062\n",
            "Epoch 3/20\n",
            "124/124 [==============================] - 20s 164ms/step - loss: 0.1876 - accuracy: 0.9206 - val_loss: 0.1986 - val_accuracy: 0.9234\n",
            "Epoch 4/20\n",
            "124/124 [==============================] - 20s 159ms/step - loss: 0.1638 - accuracy: 0.9346 - val_loss: 0.1855 - val_accuracy: 0.9224\n",
            "Epoch 5/20\n",
            "124/124 [==============================] - 20s 158ms/step - loss: 0.1681 - accuracy: 0.9295 - val_loss: 0.2038 - val_accuracy: 0.9052\n",
            "Epoch 6/20\n",
            "124/124 [==============================] - 21s 170ms/step - loss: 0.1518 - accuracy: 0.9348 - val_loss: 0.1894 - val_accuracy: 0.9133\n",
            "Epoch 7/20\n",
            "124/124 [==============================] - 22s 176ms/step - loss: 0.1417 - accuracy: 0.9435 - val_loss: 0.1724 - val_accuracy: 0.9315\n",
            "Epoch 8/20\n",
            "124/124 [==============================] - 22s 174ms/step - loss: 0.1282 - accuracy: 0.9498 - val_loss: 0.1661 - val_accuracy: 0.9315\n",
            "Epoch 9/20\n",
            "124/124 [==============================] - 20s 160ms/step - loss: 0.1212 - accuracy: 0.9544 - val_loss: 0.1838 - val_accuracy: 0.9254\n",
            "Epoch 10/20\n",
            "124/124 [==============================] - 21s 169ms/step - loss: 0.1160 - accuracy: 0.9579 - val_loss: 0.1653 - val_accuracy: 0.9315\n",
            "Epoch 11/20\n",
            "124/124 [==============================] - 21s 169ms/step - loss: 0.1145 - accuracy: 0.9569 - val_loss: 0.1778 - val_accuracy: 0.9284\n",
            "Epoch 12/20\n",
            "124/124 [==============================] - 21s 170ms/step - loss: 0.1116 - accuracy: 0.9564 - val_loss: 0.2204 - val_accuracy: 0.9173\n",
            "Epoch 13/20\n",
            "124/124 [==============================] - 22s 174ms/step - loss: 0.1040 - accuracy: 0.9612 - val_loss: 0.1754 - val_accuracy: 0.9345\n",
            "Epoch 14/20\n",
            "124/124 [==============================] - 20s 160ms/step - loss: 0.1045 - accuracy: 0.9602 - val_loss: 0.1774 - val_accuracy: 0.9345\n",
            "Epoch 15/20\n",
            "124/124 [==============================] - 21s 168ms/step - loss: 0.0961 - accuracy: 0.9635 - val_loss: 0.1698 - val_accuracy: 0.9325\n",
            "Epoch 16/20\n",
            "124/124 [==============================] - 20s 159ms/step - loss: 0.0972 - accuracy: 0.9640 - val_loss: 0.1681 - val_accuracy: 0.9335\n",
            "Epoch 17/20\n",
            "124/124 [==============================] - 20s 162ms/step - loss: 0.0814 - accuracy: 0.9698 - val_loss: 0.1591 - val_accuracy: 0.9355\n",
            "Epoch 18/20\n",
            "124/124 [==============================] - 21s 171ms/step - loss: 0.0837 - accuracy: 0.9703 - val_loss: 0.1668 - val_accuracy: 0.9365\n",
            "Epoch 19/20\n",
            "124/124 [==============================] - 20s 162ms/step - loss: 0.0776 - accuracy: 0.9716 - val_loss: 0.1592 - val_accuracy: 0.9395\n",
            "Epoch 20/20\n",
            "124/124 [==============================] - 21s 170ms/step - loss: 0.0710 - accuracy: 0.9752 - val_loss: 0.1767 - val_accuracy: 0.9375\n",
            "\n",
            "Training model with optimizer: adadelta\n",
            "Epoch 1/20\n",
            "124/124 [==============================] - 23s 172ms/step - loss: 0.7016 - accuracy: 0.5730 - val_loss: 0.5469 - val_accuracy: 0.8246\n",
            "Epoch 2/20\n",
            "124/124 [==============================] - 21s 171ms/step - loss: 0.5479 - accuracy: 0.7282 - val_loss: 0.4631 - val_accuracy: 0.8276\n",
            "Epoch 3/20\n",
            "124/124 [==============================] - 20s 160ms/step - loss: 0.4723 - accuracy: 0.7918 - val_loss: 0.4214 - val_accuracy: 0.8417\n",
            "Epoch 4/20\n",
            "124/124 [==============================] - 20s 160ms/step - loss: 0.4330 - accuracy: 0.8248 - val_loss: 0.3943 - val_accuracy: 0.8438\n",
            "Epoch 5/20\n",
            "124/124 [==============================] - 20s 160ms/step - loss: 0.4087 - accuracy: 0.8283 - val_loss: 0.3767 - val_accuracy: 0.8417\n",
            "Epoch 6/20\n",
            "124/124 [==============================] - 20s 160ms/step - loss: 0.3871 - accuracy: 0.8519 - val_loss: 0.3629 - val_accuracy: 0.8488\n",
            "Epoch 7/20\n",
            "124/124 [==============================] - 21s 170ms/step - loss: 0.3702 - accuracy: 0.8540 - val_loss: 0.3506 - val_accuracy: 0.8538\n",
            "Epoch 8/20\n",
            "124/124 [==============================] - 21s 169ms/step - loss: 0.3469 - accuracy: 0.8666 - val_loss: 0.3407 - val_accuracy: 0.8599\n",
            "Epoch 9/20\n",
            "124/124 [==============================] - 21s 172ms/step - loss: 0.3448 - accuracy: 0.8712 - val_loss: 0.3330 - val_accuracy: 0.8669\n",
            "Epoch 10/20\n",
            "124/124 [==============================] - 20s 161ms/step - loss: 0.3390 - accuracy: 0.8715 - val_loss: 0.3246 - val_accuracy: 0.8679\n",
            "Epoch 11/20\n",
            "124/124 [==============================] - 20s 164ms/step - loss: 0.3263 - accuracy: 0.8763 - val_loss: 0.3203 - val_accuracy: 0.8679\n",
            "Epoch 12/20\n",
            "124/124 [==============================] - 20s 161ms/step - loss: 0.3224 - accuracy: 0.8768 - val_loss: 0.3136 - val_accuracy: 0.8720\n",
            "Epoch 13/20\n",
            "124/124 [==============================] - 20s 159ms/step - loss: 0.3172 - accuracy: 0.8785 - val_loss: 0.3096 - val_accuracy: 0.8740\n",
            "Epoch 14/20\n",
            "124/124 [==============================] - 21s 169ms/step - loss: 0.3055 - accuracy: 0.8864 - val_loss: 0.3063 - val_accuracy: 0.8750\n",
            "Epoch 15/20\n",
            "124/124 [==============================] - 20s 161ms/step - loss: 0.3040 - accuracy: 0.8859 - val_loss: 0.3038 - val_accuracy: 0.8780\n",
            "Epoch 16/20\n",
            "124/124 [==============================] - 20s 161ms/step - loss: 0.2979 - accuracy: 0.8877 - val_loss: 0.3014 - val_accuracy: 0.8780\n",
            "Epoch 17/20\n",
            "124/124 [==============================] - 21s 170ms/step - loss: 0.2964 - accuracy: 0.8884 - val_loss: 0.2983 - val_accuracy: 0.8780\n",
            "Epoch 18/20\n",
            "124/124 [==============================] - 20s 160ms/step - loss: 0.2901 - accuracy: 0.8889 - val_loss: 0.2951 - val_accuracy: 0.8790\n",
            "Epoch 19/20\n",
            "124/124 [==============================] - 20s 162ms/step - loss: 0.2917 - accuracy: 0.8872 - val_loss: 0.2931 - val_accuracy: 0.8800\n",
            "Epoch 20/20\n",
            "124/124 [==============================] - 20s 161ms/step - loss: 0.2893 - accuracy: 0.8920 - val_loss: 0.2915 - val_accuracy: 0.8790\n",
            "\n",
            "Training model with optimizer: rmsprop\n",
            "Epoch 1/20\n",
            "124/124 [==============================] - 22s 172ms/step - loss: 0.7046 - accuracy: 0.8268 - val_loss: 0.3625 - val_accuracy: 0.8599\n",
            "Epoch 2/20\n",
            "124/124 [==============================] - 21s 169ms/step - loss: 0.2928 - accuracy: 0.8856 - val_loss: 0.2265 - val_accuracy: 0.8891\n",
            "Epoch 3/20\n",
            "124/124 [==============================] - 21s 169ms/step - loss: 0.2501 - accuracy: 0.8996 - val_loss: 0.2484 - val_accuracy: 0.8881\n",
            "Epoch 4/20\n",
            "124/124 [==============================] - 21s 170ms/step - loss: 0.2235 - accuracy: 0.9062 - val_loss: 0.2336 - val_accuracy: 0.8982\n",
            "Epoch 5/20\n",
            "124/124 [==============================] - 20s 159ms/step - loss: 0.2122 - accuracy: 0.9097 - val_loss: 0.2177 - val_accuracy: 0.8952\n",
            "Epoch 6/20\n",
            "124/124 [==============================] - 21s 173ms/step - loss: 0.1966 - accuracy: 0.9232 - val_loss: 0.1845 - val_accuracy: 0.9183\n",
            "Epoch 7/20\n",
            "124/124 [==============================] - 20s 161ms/step - loss: 0.1848 - accuracy: 0.9184 - val_loss: 0.1929 - val_accuracy: 0.9093\n",
            "Epoch 8/20\n",
            "124/124 [==============================] - 21s 169ms/step - loss: 0.1707 - accuracy: 0.9249 - val_loss: 0.2480 - val_accuracy: 0.9062\n",
            "Epoch 9/20\n",
            "124/124 [==============================] - 20s 158ms/step - loss: 0.1611 - accuracy: 0.9331 - val_loss: 0.2086 - val_accuracy: 0.9264\n",
            "Epoch 10/20\n",
            "124/124 [==============================] - 21s 172ms/step - loss: 0.1642 - accuracy: 0.9310 - val_loss: 0.1997 - val_accuracy: 0.9244\n",
            "Epoch 11/20\n",
            "124/124 [==============================] - 20s 161ms/step - loss: 0.1570 - accuracy: 0.9326 - val_loss: 0.1990 - val_accuracy: 0.9244\n",
            "Epoch 12/20\n",
            "124/124 [==============================] - 20s 158ms/step - loss: 0.1405 - accuracy: 0.9430 - val_loss: 0.2280 - val_accuracy: 0.9274\n",
            "Epoch 13/20\n",
            "124/124 [==============================] - 21s 169ms/step - loss: 0.1501 - accuracy: 0.9384 - val_loss: 0.2409 - val_accuracy: 0.9224\n",
            "Epoch 14/20\n",
            "124/124 [==============================] - 21s 168ms/step - loss: 0.1340 - accuracy: 0.9399 - val_loss: 0.1895 - val_accuracy: 0.9315\n",
            "Epoch 15/20\n",
            "124/124 [==============================] - 20s 164ms/step - loss: 0.1323 - accuracy: 0.9455 - val_loss: 0.1876 - val_accuracy: 0.9284\n",
            "Epoch 16/20\n",
            "124/124 [==============================] - 21s 172ms/step - loss: 0.1282 - accuracy: 0.9468 - val_loss: 0.2111 - val_accuracy: 0.9143\n",
            "Epoch 17/20\n",
            "124/124 [==============================] - 21s 168ms/step - loss: 0.1194 - accuracy: 0.9516 - val_loss: 0.2569 - val_accuracy: 0.9284\n",
            "Epoch 18/20\n",
            "124/124 [==============================] - 20s 159ms/step - loss: 0.1260 - accuracy: 0.9501 - val_loss: 0.1847 - val_accuracy: 0.9335\n",
            "Epoch 19/20\n",
            "124/124 [==============================] - 21s 170ms/step - loss: 0.1229 - accuracy: 0.9485 - val_loss: 0.2291 - val_accuracy: 0.9194\n",
            "Epoch 20/20\n",
            "124/124 [==============================] - 20s 160ms/step - loss: 0.1159 - accuracy: 0.9528 - val_loss: 0.2143 - val_accuracy: 0.9395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate each model\n",
        "from tensorflow.keras.models import load_model\n",
        "for optimizer_name in optimizers:\n",
        "    model_path = f'/content/drive/MyDrive/Colab Notebooks/malware_detector_vgg16_{optimizer_name}.h5'\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Evaluate the model on the \"test\" set\n",
        "    test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)\n",
        "\n",
        "\n",
        "\n",
        "    print(f'Model with optimizer {optimizer_name} - Test accuracy: {test_acc}, Test loss: {test_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjcrmqVaFiWC",
        "outputId": "bf289805-45d1-472c-e984-e8eeb0c837b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-450182ca2347>:8: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model with optimizer adam - Test accuracy: 0.9354838728904724, Test loss: 0.17193792760372162\n",
            "Model with optimizer adamax - Test accuracy: 0.9375, Test loss: 0.17721770703792572\n",
            "Model with optimizer adadelta - Test accuracy: 0.8810483813285828, Test loss: 0.2884858250617981\n",
            "Model with optimizer rmsprop - Test accuracy: 0.9395161271095276, Test loss: 0.21396440267562866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Function to preprocess an image for prediction\n",
        "def preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Normalize the pixel values to be between 0 and 1\n",
        "    return img_array\n",
        "\n",
        "# Load each trained model and make predictions\n",
        "optimizers = ['adam', 'adamax', 'adadelta', 'rmsprop']\n",
        "\n",
        "for optimizer_name in optimizers:\n",
        "    # Load the model\n",
        "    model_path = f'/content/drive/MyDrive/Colab Notebooks/malware_detector_vgg16_{optimizer_name}.h5'\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Choose a random image from the test folder\n",
        "    test_images_folder = '/content/dataset/test'\n",
        "    class_folders = ['Benign', 'Malware']\n",
        "    random_class = random.choice(class_folders)\n",
        "    random_image_path = os.path.join(test_images_folder, random_class, random.choice(os.listdir(os.path.join(test_images_folder, random_class))))\n",
        "\n",
        "    # Preprocess the image\n",
        "    img = preprocess_image(random_image_path)\n",
        "\n",
        "    # Make a prediction\n",
        "    prediction = model.predict(img)\n",
        "\n",
        "    # Display the result\n",
        "    print(f'Model with optimizer {optimizer_name}:')\n",
        "    if prediction[0][0] > 0.5:\n",
        "        print(\"Predicted: Malware\")\n",
        "    else:\n",
        "        print(\"Predicted: Benign\")\n",
        "    print('---')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zA4Db-MNwHF",
        "outputId": "9923d76a-d6f3-4ae8-e689-4404836eca81"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7cec9eb6b6d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 145ms/step\n",
            "Model with optimizer adam:\n",
            "Predicted: Benign\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7cec9e9889d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 134ms/step\n",
            "Model with optimizer adamax:\n",
            "Predicted: Benign\n",
            "---\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "Model with optimizer adadelta:\n",
            "Predicted: Benign\n",
            "---\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "Model with optimizer rmsprop:\n",
            "Predicted: Benign\n",
            "---\n"
          ]
        }
      ]
    }
  ]
}